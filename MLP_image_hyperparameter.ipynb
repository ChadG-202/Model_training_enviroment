{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "intimate-status",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 29s]\n",
      "val_accuracy: 0.0\n",
      "\n",
      "Best val_accuracy So Far: 0.9000000059604645\n",
      "Total elapsed time: 00h 08m 18s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Results summary\n",
      "Results in hyperband\\MLP8\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 352\n",
      "dense_activation: sigmoid\n",
      "dropout: 0.05\n",
      "units_2: 192\n",
      "dense_activation_2: relu\n",
      "dropout_2: 0.05\n",
      "units_3: 384\n",
      "dense_activation_3: relu\n",
      "dropout_3: 0.2\n",
      "units_4: 256\n",
      "dense_activation_4: relu\n",
      "dropout_4: 0.25\n",
      "learning_rate: 0.00036151371126048177\n",
      "tuner/epochs: 15\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 123c3cbd230a2e6f294d5828efd10f66\n",
      "Score: 0.9000000059604645\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 448\n",
      "dense_activation: tanh\n",
      "dropout: 0.2\n",
      "units_2: 256\n",
      "dense_activation_2: sigmoid\n",
      "dropout_2: 0.25\n",
      "units_3: 224\n",
      "dense_activation_3: relu\n",
      "dropout_3: 0.25\n",
      "units_4: 192\n",
      "dense_activation_4: sigmoid\n",
      "dropout_4: 0.0\n",
      "learning_rate: 0.00026384087338560336\n",
      "tuner/epochs: 15\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.8696969747543335\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 320\n",
      "dense_activation: sigmoid\n",
      "dropout: 0.2\n",
      "units_2: 96\n",
      "dense_activation_2: sigmoid\n",
      "dropout_2: 0.05\n",
      "units_3: 288\n",
      "dense_activation_3: relu\n",
      "dropout_3: 0.0\n",
      "units_4: 128\n",
      "dense_activation_4: relu\n",
      "dropout_4: 0.35000000000000003\n",
      "learning_rate: 0.0003243806953412315\n",
      "tuner/epochs: 15\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: a0eec4a11c132bfa4a40b92d2dbf8cf4\n",
      "Score: 0.8560605943202972\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 256\n",
      "dense_activation: tanh\n",
      "dropout: 0.35000000000000003\n",
      "units_2: 320\n",
      "dense_activation_2: tanh\n",
      "dropout_2: 0.5\n",
      "units_3: 128\n",
      "dense_activation_3: sigmoid\n",
      "dropout_3: 0.0\n",
      "units_4: 448\n",
      "dense_activation_4: tanh\n",
      "dropout_4: 0.5\n",
      "learning_rate: 0.0002421696251742364\n",
      "tuner/epochs: 15\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.7371212244033813\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 352\n",
      "dense_activation: sigmoid\n",
      "dropout: 0.05\n",
      "units_2: 192\n",
      "dense_activation_2: relu\n",
      "dropout_2: 0.05\n",
      "units_3: 384\n",
      "dense_activation_3: relu\n",
      "dropout_3: 0.2\n",
      "units_4: 256\n",
      "dense_activation_4: relu\n",
      "dropout_4: 0.25\n",
      "learning_rate: 0.00036151371126048177\n",
      "tuner/epochs: 5\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.5909090936183929\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 352\n",
      "dense_activation: relu\n",
      "dropout: 0.25\n",
      "units_2: 288\n",
      "dense_activation_2: relu\n",
      "dropout_2: 0.05\n",
      "units_3: 320\n",
      "dense_activation_3: sigmoid\n",
      "dropout_3: 0.25\n",
      "units_4: 192\n",
      "dense_activation_4: sigmoid\n",
      "dropout_4: 0.30000000000000004\n",
      "learning_rate: 0.00026284667590287193\n",
      "tuner/epochs: 15\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 4dfeca57b79f73d48a6cbe73f69d6d00\n",
      "Score: 0.48181818425655365\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 96\n",
      "dense_activation: relu\n",
      "dropout: 0.1\n",
      "units_2: 160\n",
      "dense_activation_2: sigmoid\n",
      "dropout_2: 0.4\n",
      "units_3: 192\n",
      "dense_activation_3: relu\n",
      "dropout_3: 0.25\n",
      "units_4: 320\n",
      "dense_activation_4: tanh\n",
      "dropout_4: 0.25\n",
      "learning_rate: 0.00032962260207930136\n",
      "tuner/epochs: 15\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 76f04fe5aafd5feaac7660d19478908a\n",
      "Score: 0.47121213376522064\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 320\n",
      "dense_activation: sigmoid\n",
      "dropout: 0.2\n",
      "units_2: 96\n",
      "dense_activation_2: sigmoid\n",
      "dropout_2: 0.05\n",
      "units_3: 288\n",
      "dense_activation_3: relu\n",
      "dropout_3: 0.0\n",
      "units_4: 128\n",
      "dense_activation_4: relu\n",
      "dropout_4: 0.35000000000000003\n",
      "learning_rate: 0.0003243806953412315\n",
      "tuner/epochs: 5\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.30000000447034836\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 416\n",
      "dense_activation: tanh\n",
      "dropout: 0.05\n",
      "units_2: 384\n",
      "dense_activation_2: tanh\n",
      "dropout_2: 0.2\n",
      "units_3: 480\n",
      "dense_activation_3: sigmoid\n",
      "dropout_3: 0.35000000000000003\n",
      "units_4: 448\n",
      "dense_activation_4: tanh\n",
      "dropout_4: 0.35000000000000003\n",
      "learning_rate: 0.0004827322539144281\n",
      "tuner/epochs: 5\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.23636363446712494\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 192\n",
      "dense_activation: sigmoid\n",
      "dropout: 0.30000000000000004\n",
      "units_2: 416\n",
      "dense_activation_2: relu\n",
      "dropout_2: 0.45\n",
      "units_3: 352\n",
      "dense_activation_3: tanh\n",
      "dropout_3: 0.5\n",
      "units_4: 480\n",
      "dense_activation_4: relu\n",
      "dropout_4: 0.45\n",
      "learning_rate: 0.0008251039755551379\n",
      "tuner/epochs: 15\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.010606060735881329\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Embedding\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from keras_tuner import HyperModel\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from keras_tuner.tuners import Hyperband\n",
    "from tensorflow import keras\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle_in = open(\"X_image.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y_image.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "X = X.astype(\"float32\")/255.0\n",
    "\n",
    "class MLPHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        \n",
    "        model.add(\n",
    "            Dense(\n",
    "                units=hp.Int(\n",
    "                    'units',\n",
    "                    min_value=32,\n",
    "                    max_value=512,\n",
    "                    step=32,\n",
    "                    default=128\n",
    "                ),\n",
    "                activation=hp.Choice(\n",
    "                    'dense_activation',\n",
    "                    values=['relu', 'tanh', 'sigmoid'],\n",
    "                    default='relu'\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        model.add(\n",
    "            Dropout(\n",
    "                rate=hp.Float(\n",
    "                    'dropout',\n",
    "                    min_value=0.0,\n",
    "                    max_value=0.5,\n",
    "                    default=0.25,\n",
    "                    step=0.05\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        model.add(\n",
    "            Dense(\n",
    "                units=hp.Int(\n",
    "                    'units_2',\n",
    "                    min_value=32,\n",
    "                    max_value=512,\n",
    "                    step=32,\n",
    "                    default=128\n",
    "                ),\n",
    "                activation=hp.Choice(\n",
    "                    'dense_activation_2',\n",
    "                    values=['relu', 'tanh', 'sigmoid'],\n",
    "                    default='relu'\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        model.add(\n",
    "            Dropout(\n",
    "                rate=hp.Float(\n",
    "                    'dropout_2',\n",
    "                    min_value=0.0,\n",
    "                    max_value=0.5,\n",
    "                    default=0.25,\n",
    "                    step=0.05\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        model.add(\n",
    "            Dense(\n",
    "                units=hp.Int(\n",
    "                    'units_3',\n",
    "                    min_value=32,\n",
    "                    max_value=512,\n",
    "                    step=32,\n",
    "                    default=128\n",
    "                ),\n",
    "                activation=hp.Choice(\n",
    "                    'dense_activation_3',\n",
    "                    values=['relu', 'tanh', 'sigmoid'],\n",
    "                    default='relu'\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        model.add(\n",
    "            Dropout(\n",
    "                rate=hp.Float(\n",
    "                    'dropout_3',\n",
    "                    min_value=0.0,\n",
    "                    max_value=0.5,\n",
    "                    default=0.25,\n",
    "                    step=0.05\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        model.add(\n",
    "            Dense(\n",
    "                units=hp.Int(\n",
    "                    'units_4',\n",
    "                    min_value=32,\n",
    "                    max_value=512,\n",
    "                    step=32,\n",
    "                    default=128\n",
    "                ),\n",
    "                activation=hp.Choice(\n",
    "                    'dense_activation_4',\n",
    "                    values=['relu', 'tanh', 'sigmoid'],\n",
    "                    default='relu'\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        model.add(\n",
    "            Dropout(\n",
    "                rate=hp.Float(\n",
    "                    'dropout_4',\n",
    "                    min_value=0.0,\n",
    "                    max_value=0.5,\n",
    "                    default=0.25,\n",
    "                    step=0.05\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=hp.Float(\n",
    "                    'learning_rate',\n",
    "                    min_value=1e-4,\n",
    "                    max_value=1e-2,\n",
    "                    sampling='LOG',\n",
    "                    default=1e-3\n",
    "            )),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n",
    "    \n",
    "NUM_CLASSES = 3  # happy neutral sad number of classes\n",
    "INPUT_SHAPE = (48, 48, 1) \n",
    "SEED = 1\n",
    "HYPERBAND_MAX_EPOCHS = 15\n",
    "MAX_TRIALS = 25\n",
    "EXECUTION_PER_TRIAL = 2\n",
    "\n",
    "hypermodel = MLPHyperModel(input_shape=INPUT_SHAPE, num_classes=NUM_CLASSES)\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    hypermodel,\n",
    "    objective='val_accuracy',\n",
    "    seed=SEED,\n",
    "    max_trials=MAX_TRIALS,\n",
    "    executions_per_trial=EXECUTION_PER_TRIAL,\n",
    "    directory='random_search',\n",
    "    project_name='MLP8'\n",
    ")\n",
    "\n",
    "tuner = Hyperband(\n",
    "    hypermodel,\n",
    "    max_epochs=HYPERBAND_MAX_EPOCHS,\n",
    "    objective='val_accuracy',\n",
    "    seed=SEED,\n",
    "    executions_per_trial=EXECUTION_PER_TRIAL,\n",
    "    directory='hyperband',\n",
    "    project_name='MLP8'\n",
    ")\n",
    "\n",
    "N_EPOCH_SEARCH = 15\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "tuner.search(X, y, batch_size=BATCH_SIZE, epochs=N_EPOCH_SEARCH, validation_split=0.2)\n",
    "\n",
    "tuner.results_summary()\n",
    "\n",
    "# Retrieve the best model.\n",
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-grade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-moses",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
